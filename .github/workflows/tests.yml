name: Testing Suite

on:
  push:
    branches: [master, main]
  pull_request:
    branches: [master, main]

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run unit tests
        run: npm run test:unit
        continue-on-error: true
        continue-on-error: true

      - name: Generate coverage report
        run: npm run test:coverage
        continue-on-error: true
        continue-on-error: true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        continue-on-error: true
        with:
          files: ./coverage/lcov.info
          flags: unit-tests
          name: unit-coverage

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Run integration tests
        run: npm run test:integration
        continue-on-error: true
        env:
          ALGOLIA_API_KEY: ${{ secrets.ALGOLIA_API_KEY }}
          ALGOLIA_INDEX: ${{ secrets.ALGOLIA_INDEX }}
          ALGOLIA_APP_ID: ${{ secrets.ALGOLIA_APP_ID }}

  e2e-tests:
    name: E2E Tests (${{ matrix.browser }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Build project
        run: npm run build

      - name: Run E2E tests
        run: npm run test:e2e -- --project=${{ matrix.browser }}
        continue-on-error: true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-results-${{ matrix.browser }}
          path: test-results/

      - name: Upload HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.browser }}
          path: playwright-report/

  performance-tests:
    name: Performance Tests (Lighthouse)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Build project
        run: npm run build

      - name: Run Lighthouse CI
        run: npm run lighthouse
        continue-on-error: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload Lighthouse results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-results
          path: .lighthouseci/

  build-validation:
    name: Build Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Build project
        run: npm run build

      - name: Check build output
        run: |
          # Verify build directory exists
          test -d docs || exit 1

          # Verify critical files exist
          test -f docs/index.html || exit 1
          test -d docs/assets || exit 1
          test -f docs/sitemap.xml || exit 1

          # Verify all versions built
          for version in master 1.9.6 1.9.5 1.9.4 1.9.3 1.5.0 1.4.1 1.4.0; do
            test -d "docs/${version}" || exit 1
          done

          echo "✅ Build validation passed"

      - name: Check bundle size
        run: |
          # Find largest JS bundle
          MAX_SIZE=512000  # 500KB in bytes
          LARGE_BUNDLES=$(find docs/assets -name "*.js" -size +${MAX_SIZE}c)

          if [ ! -z "$LARGE_BUNDLES" ]; then
            echo "❌ Found bundles larger than 500KB:"
            echo "$LARGE_BUNDLES"
            exit 1
          fi

          echo "✅ Bundle size check passed"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: docs/
          retention-days: 7

  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --legacy-peer-deps

      - name: Install Playwright
        run: npx playwright install --with-deps chromium

      - name: Build project
        run: npm run build

      - name: Run accessibility tests
        run: |
          # Start server in background
          npx http-server docs -p 8080 &
          SERVER_PID=$!

          # Wait for server
          sleep 5

          # Run axe-core accessibility tests (would need to be created)
          # npm run test:a11y

          # Kill server
          kill $SERVER_PID

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, build-validation]
    if: always()

    steps:
      - name: Check test results
        run: |
          if [ "${{ needs.unit-tests.result }}" != "success" ]; then
            echo "❌ Unit tests failed"
            exit 1
          fi
          if [ "${{ needs.integration-tests.result }}" != "success" ]; then
            echo "❌ Integration tests failed"
            exit 1
          fi
          if [ "${{ needs.e2e-tests.result }}" != "success" ]; then
            echo "❌ E2E tests failed"
            exit 1
          fi
          if [ "${{ needs.performance-tests.result }}" != "success" ]; then
            echo "⚠️  Performance tests failed (warning only)"
          fi
          if [ "${{ needs.build-validation.result }}" != "success" ]; then
            echo "❌ Build validation failed"
            exit 1
          fi

          echo "✅ All critical tests passed!"
